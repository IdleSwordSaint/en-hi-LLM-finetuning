#en-hi-llm-finetuning

Fine-tuning Lightweight Transformer Models for English to Hindi Translation using the IIT Bombay Parallel Corpus.

â¸»

ğŸ“Œ Overview

This project demonstrates the fine-tuning of pretrained transformer models for English-to-Hindi machine translation, with a focus on efficiency and performance. The core of the work involves adapting the MarianMT (Helsinki-NLP/opus-mt-en-hi) model to the IIT Bombay English-Hindi Parallel Corpus, using techniques like LoRA (Low-Rank Adaptation) to make training feasible on resource-constrained hardware.

â¸»

ğŸ—‚ï¸ Dataset
	â€¢	IIT Bombay English-Hindi Parallel Corpus
	â€¢	Contains ~1.6 million high-quality sentence pairs.
	â€¢	Available here.
	â€¢	Preprocessed using:
	â€¢	Tokenization
	â€¢	Sequence truncation (for maximum model input length)

â¸»

ğŸ§  Models & Techniques

âœ… Fine-tuned Base Model
	â€¢	Helsinki-NLP/opus-mt-en-hi (MarianMT)
Pretrained model for English to Hindi machine translation, fine-tuned on the IITB dataset.

âš™ï¸ Parameter-Efficient Fine-tuning
	â€¢	LoRA (Low-Rank Adaptation)
	â€¢	Reduced trainable parameters by 99.2% (from 75.8M â†’ 0.59M)
	â€¢	Enabled efficient training on low-resource hardware setups

ğŸ§ª Optimization
	â€¢	Optimizer: AdamW
	â€¢	Learning Rate Scheduler: Linear decay with warmup
	â€¢	Evaluation Metrics:
	â€¢	BLEU
	â€¢	METEOR
	â€¢	ROUGE

â¸»

ğŸ“ˆ Results

Significant performance improvements were observed after fine-tuning:

Metric	Before	After	Improvement
METEOR	0.27	0.32	+18.8%
BLEU	9.8	12.0	+22.7%


â¸»

ğŸš€ Quickstart

1. Clone the Repository

git clone https://github.com/your-username/en-hi-llm-finetuning.git
cd en-hi-llm-finetuning

2. Install Dependencies

pip install -r requirements.txt

3. Preprocess Dataset

Prepare and tokenize the IITB dataset.

python scripts/preprocess.py --data_dir data/iitb --tokenizer helsinki

4. Fine-tune the Model

python train.py --model helsinki --use_lora --output_dir checkpoints/opus-mt-en-hi-lora

5. Evaluate

python evaluate.py --model checkpoints/opus-mt-en-hi-lora

-----------

ğŸ“„ License

This project is licensed under the MIT License.
Note: The IIT Bombay dataset is released under a separate license â€” please refer to their official terms.

â¸»

ğŸ™Œ Acknowledgements
	â€¢	IIT Bombay English-Hindi Parallel Corpus
	â€¢	Helsinki-NLP / MarianMT models
	â€¢	LoRA: Low-Rank Adaptation of Large Language Models
	â€¢	Hugging Face Transformers
